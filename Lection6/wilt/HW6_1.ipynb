{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e558ab3-1d22-449d-8bf9-352dcc9e445b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>GLCM_pan</th>\n",
       "      <th>Mean_Green</th>\n",
       "      <th>Mean_Red</th>\n",
       "      <th>Mean_NIR</th>\n",
       "      <th>SD_pan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w</td>\n",
       "      <td>120.362774</td>\n",
       "      <td>205.500000</td>\n",
       "      <td>119.395349</td>\n",
       "      <td>416.581395</td>\n",
       "      <td>20.676318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w</td>\n",
       "      <td>124.739583</td>\n",
       "      <td>202.800000</td>\n",
       "      <td>115.333333</td>\n",
       "      <td>354.333333</td>\n",
       "      <td>16.707151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>w</td>\n",
       "      <td>134.691964</td>\n",
       "      <td>199.285714</td>\n",
       "      <td>116.857143</td>\n",
       "      <td>477.857143</td>\n",
       "      <td>22.496712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class    GLCM_pan  Mean_Green    Mean_Red    Mean_NIR     SD_pan\n",
       "0     w  120.362774  205.500000  119.395349  416.581395  20.676318\n",
       "1     w  124.739583  202.800000  115.333333  354.333333  16.707151\n",
       "2     w  134.691964  199.285714  116.857143  477.857143  22.496712"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, precision_score, roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"training.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c8f83d3-70b3-4cf6-8c33-513367816c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4339, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea4e94bd-e00d-47d2-af8d-d5e074b7c647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n    4265\n",
       "w      74\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, 0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6969af40-b6e1-4ea7-9816-e06099ee8efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({'class': {'w': 1, 'n': 0}}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9d7600c-8844-4ac4-8e92-4c1f66f78798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4265\n",
       "1      74\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, 0].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a482cdf-c965-418a-9b68-239210843068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>GLCM_pan</th>\n",
       "      <th>Mean_Green</th>\n",
       "      <th>Mean_Red</th>\n",
       "      <th>Mean_NIR</th>\n",
       "      <th>SD_pan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4339.000000</td>\n",
       "      <td>4339.000000</td>\n",
       "      <td>4339.000000</td>\n",
       "      <td>4339.000000</td>\n",
       "      <td>4339.000000</td>\n",
       "      <td>4339.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.017055</td>\n",
       "      <td>126.831298</td>\n",
       "      <td>233.906908</td>\n",
       "      <td>117.292439</td>\n",
       "      <td>534.104683</td>\n",
       "      <td>24.924588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.129490</td>\n",
       "      <td>13.735836</td>\n",
       "      <td>60.757687</td>\n",
       "      <td>60.711159</td>\n",
       "      <td>154.495500</td>\n",
       "      <td>11.008303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.625000</td>\n",
       "      <td>59.142857</td>\n",
       "      <td>86.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>118.589080</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>91.975244</td>\n",
       "      <td>422.875000</td>\n",
       "      <td>18.009143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>127.479167</td>\n",
       "      <td>221.454545</td>\n",
       "      <td>101.727273</td>\n",
       "      <td>528.500000</td>\n",
       "      <td>23.612444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>135.043591</td>\n",
       "      <td>241.791304</td>\n",
       "      <td>116.866071</td>\n",
       "      <td>643.087037</td>\n",
       "      <td>29.899148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>183.281250</td>\n",
       "      <td>955.714286</td>\n",
       "      <td>746.333333</td>\n",
       "      <td>1005.516129</td>\n",
       "      <td>156.508431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             class     GLCM_pan   Mean_Green     Mean_Red     Mean_NIR  \\\n",
       "count  4339.000000  4339.000000  4339.000000  4339.000000  4339.000000   \n",
       "mean      0.017055   126.831298   233.906908   117.292439   534.104683   \n",
       "std       0.129490    13.735836    60.757687    60.711159   154.495500   \n",
       "min       0.000000     0.000000   164.625000    59.142857    86.500000   \n",
       "25%       0.000000   118.589080   206.000000    91.975244   422.875000   \n",
       "50%       0.000000   127.479167   221.454545   101.727273   528.500000   \n",
       "75%       0.000000   135.043591   241.791304   116.866071   643.087037   \n",
       "max       1.000000   183.281250   955.714286   746.333333  1005.516129   \n",
       "\n",
       "            SD_pan  \n",
       "count  4339.000000  \n",
       "mean     24.924588  \n",
       "std      11.008303  \n",
       "min       0.000000  \n",
       "25%      18.009143  \n",
       "50%      23.612444  \n",
       "75%      29.899148  \n",
       "max     156.508431  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b38968a9-d150-4ff7-947a-52cb61dc4b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(set(df.iloc[:, 1:].columns))\n",
    "base_cols = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41a1cf31-7473-4ca9-81ad-efddc88f6743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_44' % (col1, col2)] = data[col1] * np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_1' % (col1, col2)] = data[col1] - data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_2' % (col1, col2)] = data[col1] + data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_3' % (col1, col2)] = data[col1] / (data[col2] + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_4' % (col1, col2)] = data[col1] * data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_11' % (col1, col2)] = data[col1] - np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_22' % (col1, col2)] = data[col1] + np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_33' % (col1, col2)] = data[col1] / (np.log(data[col2] + 1) + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_44' % (col1, col2)] = data[col1] * np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_1' % (col1, col2)] = data[col1] - data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_2' % (col1, col2)] = data[col1] + data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_3' % (col1, col2)] = data[col1] / (data[col2] + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_4' % (col1, col2)] = data[col1] * data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_11' % (col1, col2)] = data[col1] - np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_22' % (col1, col2)] = data[col1] + np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_33' % (col1, col2)] = data[col1] / (np.log(data[col2] + 1) + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_44' % (col1, col2)] = data[col1] * np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_1' % (col1, col2)] = data[col1] - data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_2' % (col1, col2)] = data[col1] + data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_3' % (col1, col2)] = data[col1] / (data[col2] + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_4' % (col1, col2)] = data[col1] * data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_11' % (col1, col2)] = data[col1] - np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_22' % (col1, col2)] = data[col1] + np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_33' % (col1, col2)] = data[col1] / (np.log(data[col2] + 1) + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_44' % (col1, col2)] = data[col1] * np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col1 + '_log'] = np.log(data[col1] + 1.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_1' % (col1, col2)] = data[col1] - data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_2' % (col1, col2)] = data[col1] + data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_3' % (col1, col2)] = data[col1] / (data[col2] + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_4' % (col1, col2)] = data[col1] * data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_11' % (col1, col2)] = data[col1] - np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_22' % (col1, col2)] = data[col1] + np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_33' % (col1, col2)] = data[col1] / (np.log(data[col2] + 1) + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_44' % (col1, col2)] = data[col1] * np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_1' % (col1, col2)] = data[col1] - data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_2' % (col1, col2)] = data[col1] + data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_3' % (col1, col2)] = data[col1] / (data[col2] + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_4' % (col1, col2)] = data[col1] * data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_11' % (col1, col2)] = data[col1] - np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_22' % (col1, col2)] = data[col1] + np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_33' % (col1, col2)] = data[col1] / (np.log(data[col2] + 1) + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_44' % (col1, col2)] = data[col1] * np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_1' % (col1, col2)] = data[col1] - data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_2' % (col1, col2)] = data[col1] + data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_3' % (col1, col2)] = data[col1] / (data[col2] + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_4' % (col1, col2)] = data[col1] * data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_11' % (col1, col2)] = data[col1] - np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_22' % (col1, col2)] = data[col1] + np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_33' % (col1, col2)] = data[col1] / (np.log(data[col2] + 1) + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_44' % (col1, col2)] = data[col1] * np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_1' % (col1, col2)] = data[col1] - data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_2' % (col1, col2)] = data[col1] + data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_3' % (col1, col2)] = data[col1] / (data[col2] + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_4' % (col1, col2)] = data[col1] * data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_11' % (col1, col2)] = data[col1] - np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_22' % (col1, col2)] = data[col1] + np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_33' % (col1, col2)] = data[col1] / (np.log(data[col2] + 1) + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_44' % (col1, col2)] = data[col1] * np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_1' % (col1, col2)] = data[col1] - data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_2' % (col1, col2)] = data[col1] + data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_3' % (col1, col2)] = data[col1] / (data[col2] + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_4' % (col1, col2)] = data[col1] * data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_11' % (col1, col2)] = data[col1] - np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_22' % (col1, col2)] = data[col1] + np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_33' % (col1, col2)] = data[col1] / (np.log(data[col2] + 1) + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_44' % (col1, col2)] = data[col1] * np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col1 + '_log'] = np.log(data[col1] + 1.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_1' % (col1, col2)] = data[col1] - data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_2' % (col1, col2)] = data[col1] + data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_3' % (col1, col2)] = data[col1] / (data[col2] + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_4' % (col1, col2)] = data[col1] * data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_11' % (col1, col2)] = data[col1] - np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_22' % (col1, col2)] = data[col1] + np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_33' % (col1, col2)] = data[col1] / (np.log(data[col2] + 1) + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_44' % (col1, col2)] = data[col1] * np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_1' % (col1, col2)] = data[col1] - data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_2' % (col1, col2)] = data[col1] + data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_3' % (col1, col2)] = data[col1] / (data[col2] + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_4' % (col1, col2)] = data[col1] * data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_11' % (col1, col2)] = data[col1] - np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_22' % (col1, col2)] = data[col1] + np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_33' % (col1, col2)] = data[col1] / (np.log(data[col2] + 1) + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_44' % (col1, col2)] = data[col1] * np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_1' % (col1, col2)] = data[col1] - data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_2' % (col1, col2)] = data[col1] + data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_3' % (col1, col2)] = data[col1] / (data[col2] + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_4' % (col1, col2)] = data[col1] * data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_11' % (col1, col2)] = data[col1] - np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_22' % (col1, col2)] = data[col1] + np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_33' % (col1, col2)] = data[col1] / (np.log(data[col2] + 1) + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_44' % (col1, col2)] = data[col1] * np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_1' % (col1, col2)] = data[col1] - data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_2' % (col1, col2)] = data[col1] + data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_3' % (col1, col2)] = data[col1] / (data[col2] + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_4' % (col1, col2)] = data[col1] * data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_11' % (col1, col2)] = data[col1] - np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_22' % (col1, col2)] = data[col1] + np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_33' % (col1, col2)] = data[col1] / (np.log(data[col2] + 1) + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_44' % (col1, col2)] = data[col1] * np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_1' % (col1, col2)] = data[col1] - data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_2' % (col1, col2)] = data[col1] + data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_3' % (col1, col2)] = data[col1] / (data[col2] + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_4' % (col1, col2)] = data[col1] * data[col2]\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_11' % (col1, col2)] = data[col1] - np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_22' % (col1, col2)] = data[col1] + np.log(data[col2] + 1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_33' % (col1, col2)] = data[col1] / (np.log(data[col2] + 1) + 0.1)\n",
      "/var/folders/g_/9v3q8zfn4dj84j48wgjpsd7c0000gn/T/ipykernel_5153/1557307549.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['%s_%s_44' % (col1, col2)] = data[col1] * np.log(data[col2] + 1)\n"
     ]
    }
   ],
   "source": [
    "def transform_data(data):\n",
    "    for i1, col1 in enumerate(base_cols):\n",
    "        data[col1 + '_log'] = np.log(data[col1] + 1.1)\n",
    "\n",
    "        for i2, col2 in enumerate(base_cols):\n",
    "            data['%s_%s_1' % (col1, col2)] = data[col1] - data[col2]\n",
    "            data['%s_%s_2' % (col1, col2)] = data[col1] + data[col2]\n",
    "            data['%s_%s_3' % (col1, col2)] = data[col1] / (data[col2] + 0.1)\n",
    "            data['%s_%s_4' % (col1, col2)] = data[col1] * data[col2]\n",
    "\n",
    "            data['%s_%s_11' % (col1, col2)] = data[col1] - np.log(data[col2] + 1)\n",
    "            data['%s_%s_22' % (col1, col2)] = data[col1] + np.log(data[col2] + 1)\n",
    "            data['%s_%s_33' % (col1, col2)] = data[col1] / (np.log(data[col2] + 1) + 0.1)\n",
    "            data['%s_%s_44' % (col1, col2)] = data[col1] * np.log(data[col2] + 1)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "df_tr = transform_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea043942-dc1d-43cb-bafd-958cdc98fbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>GLCM_pan</th>\n",
       "      <th>Mean_Green</th>\n",
       "      <th>Mean_Red</th>\n",
       "      <th>Mean_NIR</th>\n",
       "      <th>SD_pan</th>\n",
       "      <th>Mean_NIR_log</th>\n",
       "      <th>Mean_NIR_Mean_NIR_1</th>\n",
       "      <th>Mean_NIR_Mean_NIR_2</th>\n",
       "      <th>Mean_NIR_Mean_NIR_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean_Red_SD_pan_33</th>\n",
       "      <th>Mean_Red_SD_pan_44</th>\n",
       "      <th>Mean_Red_Mean_Red_1</th>\n",
       "      <th>Mean_Red_Mean_Red_2</th>\n",
       "      <th>Mean_Red_Mean_Red_3</th>\n",
       "      <th>Mean_Red_Mean_Red_4</th>\n",
       "      <th>Mean_Red_Mean_Red_11</th>\n",
       "      <th>Mean_Red_Mean_Red_22</th>\n",
       "      <th>Mean_Red_Mean_Red_33</th>\n",
       "      <th>Mean_Red_Mean_Red_44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>120.362774</td>\n",
       "      <td>205.500000</td>\n",
       "      <td>119.395349</td>\n",
       "      <td>416.581395</td>\n",
       "      <td>20.676318</td>\n",
       "      <td>6.034719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>833.162791</td>\n",
       "      <td>0.999760</td>\n",
       "      <td>...</td>\n",
       "      <td>37.590386</td>\n",
       "      <td>367.286401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>238.790698</td>\n",
       "      <td>0.999163</td>\n",
       "      <td>14255.249315</td>\n",
       "      <td>114.604568</td>\n",
       "      <td>124.186130</td>\n",
       "      <td>24.412328</td>\n",
       "      <td>571.996957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>124.739583</td>\n",
       "      <td>202.800000</td>\n",
       "      <td>115.333333</td>\n",
       "      <td>354.333333</td>\n",
       "      <td>16.707151</td>\n",
       "      <td>5.873338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>708.666667</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>...</td>\n",
       "      <td>38.780952</td>\n",
       "      <td>331.464374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.666667</td>\n",
       "      <td>0.999134</td>\n",
       "      <td>13301.777770</td>\n",
       "      <td>110.576874</td>\n",
       "      <td>120.089793</td>\n",
       "      <td>23.748439</td>\n",
       "      <td>548.578344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>134.691964</td>\n",
       "      <td>199.285714</td>\n",
       "      <td>116.857143</td>\n",
       "      <td>477.857143</td>\n",
       "      <td>22.496712</td>\n",
       "      <td>6.171611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>955.714286</td>\n",
       "      <td>0.999791</td>\n",
       "      <td>...</td>\n",
       "      <td>35.880304</td>\n",
       "      <td>368.901697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.714286</td>\n",
       "      <td>0.999145</td>\n",
       "      <td>13655.591847</td>\n",
       "      <td>112.087670</td>\n",
       "      <td>121.626616</td>\n",
       "      <td>23.997902</td>\n",
       "      <td>557.347016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class    GLCM_pan  Mean_Green    Mean_Red    Mean_NIR     SD_pan  \\\n",
       "0      1  120.362774  205.500000  119.395349  416.581395  20.676318   \n",
       "1      1  124.739583  202.800000  115.333333  354.333333  16.707151   \n",
       "2      1  134.691964  199.285714  116.857143  477.857143  22.496712   \n",
       "\n",
       "   Mean_NIR_log  Mean_NIR_Mean_NIR_1  Mean_NIR_Mean_NIR_2  \\\n",
       "0      6.034719                  0.0           833.162791   \n",
       "1      5.873338                  0.0           708.666667   \n",
       "2      6.171611                  0.0           955.714286   \n",
       "\n",
       "   Mean_NIR_Mean_NIR_3  ...  Mean_Red_SD_pan_33  Mean_Red_SD_pan_44  \\\n",
       "0             0.999760  ...           37.590386          367.286401   \n",
       "1             0.999718  ...           38.780952          331.464374   \n",
       "2             0.999791  ...           35.880304          368.901697   \n",
       "\n",
       "   Mean_Red_Mean_Red_1  Mean_Red_Mean_Red_2  Mean_Red_Mean_Red_3  \\\n",
       "0                  0.0           238.790698             0.999163   \n",
       "1                  0.0           230.666667             0.999134   \n",
       "2                  0.0           233.714286             0.999145   \n",
       "\n",
       "   Mean_Red_Mean_Red_4  Mean_Red_Mean_Red_11  Mean_Red_Mean_Red_22  \\\n",
       "0         14255.249315            114.604568            124.186130   \n",
       "1         13301.777770            110.576874            120.089793   \n",
       "2         13655.591847            112.087670            121.626616   \n",
       "\n",
       "   Mean_Red_Mean_Red_33  Mean_Red_Mean_Red_44  \n",
       "0             24.412328            571.996957  \n",
       "1             23.748439            548.578344  \n",
       "2             23.997902            557.347016  \n",
       "\n",
       "[3 rows x 211 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d3b1c53-7fee-419d-92d7-8292aa520136",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = df.iloc[:,1:]\n",
    "y_data = df.iloc[:,0]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d44ef50-b43a-4b83-aaf7-43fb1f79512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "y_predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27ca792f-da6b-475f-9557-780b7a986dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification results:\n",
      "f1: 90.00%\n",
      "roc: 94.94%\n",
      "recall: 90.00%\n",
      "precision: 90.00%\n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "def evaluate_results(y_test, y_predict):\n",
    "    print('Classification results:')\n",
    "    f1 = f1_score(y_test, y_predict)\n",
    "    print(\"f1: %.2f%%\" % (f1 * 100.0)) \n",
    "    roc = roc_auc_score(y_test, y_predict)\n",
    "    print(\"roc: %.2f%%\" % (roc * 100.0)) \n",
    "    rec = recall_score(y_test, y_predict, average='binary')\n",
    "    print(\"recall: %.2f%%\" % (rec * 100.0)) \n",
    "    prc = precision_score(y_test, y_predict, average='binary')\n",
    "    print(\"precision: %.2f%%\" % (prc * 100.0)) \n",
    "    metrics.append([f1, roc, rec, prc])\n",
    "    \n",
    "evaluate_results(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd0c0d41-6d52-4d58-9ca8-17538b2fe86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 19/74 as positives and unlabeling the rest\n"
     ]
    }
   ],
   "source": [
    "mod_data = df_tr.copy()\n",
    "#mod_data = df.copy()\n",
    "#get the indices of the positives samples\n",
    "pos_ind = np.where(mod_data.iloc[:,0].values == 1)[0]\n",
    "#shuffle them\n",
    "np.random.shuffle(pos_ind)\n",
    "# leave just 25% of the positives marked\n",
    "pos_sample_len = int(np.ceil(0.25 * len(pos_ind)))\n",
    "print(f'Using {pos_sample_len}/{len(pos_ind)} as positives and unlabeling the rest')\n",
    "pos_sample = pos_ind[:pos_sample_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f51a3ff-8e92-4218-ab0e-304d4c920f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target variable:\n",
      " -1    4320\n",
      " 1      19\n",
      "Name: class_test, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mod_data['class_test'] = -1\n",
    "mod_data.loc[pos_sample,'class_test'] = 1\n",
    "print('target variable:\\n', mod_data.iloc[:,-1].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "918df1ca-db84-4c4a-954f-31b2a7fcb3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>GLCM_pan</th>\n",
       "      <th>Mean_Green</th>\n",
       "      <th>Mean_Red</th>\n",
       "      <th>Mean_NIR</th>\n",
       "      <th>SD_pan</th>\n",
       "      <th>Mean_NIR_log</th>\n",
       "      <th>Mean_NIR_Mean_NIR_1</th>\n",
       "      <th>Mean_NIR_Mean_NIR_2</th>\n",
       "      <th>Mean_NIR_Mean_NIR_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean_Red_SD_pan_44</th>\n",
       "      <th>Mean_Red_Mean_Red_1</th>\n",
       "      <th>Mean_Red_Mean_Red_2</th>\n",
       "      <th>Mean_Red_Mean_Red_3</th>\n",
       "      <th>Mean_Red_Mean_Red_4</th>\n",
       "      <th>Mean_Red_Mean_Red_11</th>\n",
       "      <th>Mean_Red_Mean_Red_22</th>\n",
       "      <th>Mean_Red_Mean_Red_33</th>\n",
       "      <th>Mean_Red_Mean_Red_44</th>\n",
       "      <th>class_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>120.362774</td>\n",
       "      <td>205.500000</td>\n",
       "      <td>119.395349</td>\n",
       "      <td>416.581395</td>\n",
       "      <td>20.676318</td>\n",
       "      <td>6.034719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>833.162791</td>\n",
       "      <td>0.999760</td>\n",
       "      <td>...</td>\n",
       "      <td>367.286401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>238.790698</td>\n",
       "      <td>0.999163</td>\n",
       "      <td>14255.249315</td>\n",
       "      <td>114.604568</td>\n",
       "      <td>124.186130</td>\n",
       "      <td>24.412328</td>\n",
       "      <td>571.996957</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>124.739583</td>\n",
       "      <td>202.800000</td>\n",
       "      <td>115.333333</td>\n",
       "      <td>354.333333</td>\n",
       "      <td>16.707151</td>\n",
       "      <td>5.873338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>708.666667</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>...</td>\n",
       "      <td>331.464374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.666667</td>\n",
       "      <td>0.999134</td>\n",
       "      <td>13301.777770</td>\n",
       "      <td>110.576874</td>\n",
       "      <td>120.089793</td>\n",
       "      <td>23.748439</td>\n",
       "      <td>548.578344</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>134.691964</td>\n",
       "      <td>199.285714</td>\n",
       "      <td>116.857143</td>\n",
       "      <td>477.857143</td>\n",
       "      <td>22.496712</td>\n",
       "      <td>6.171611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>955.714286</td>\n",
       "      <td>0.999791</td>\n",
       "      <td>...</td>\n",
       "      <td>368.901697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.714286</td>\n",
       "      <td>0.999145</td>\n",
       "      <td>13655.591847</td>\n",
       "      <td>112.087670</td>\n",
       "      <td>121.626616</td>\n",
       "      <td>23.997902</td>\n",
       "      <td>557.347016</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>127.946309</td>\n",
       "      <td>178.368421</td>\n",
       "      <td>92.368421</td>\n",
       "      <td>278.473684</td>\n",
       "      <td>14.977453</td>\n",
       "      <td>5.633266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>556.947368</td>\n",
       "      <td>0.999641</td>\n",
       "      <td>...</td>\n",
       "      <td>255.969387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184.736842</td>\n",
       "      <td>0.998919</td>\n",
       "      <td>8531.925207</td>\n",
       "      <td>87.831868</td>\n",
       "      <td>96.904974</td>\n",
       "      <td>19.921786</td>\n",
       "      <td>419.034255</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>135.431548</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>112.690476</td>\n",
       "      <td>532.952381</td>\n",
       "      <td>17.604193</td>\n",
       "      <td>6.280494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1065.904762</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>...</td>\n",
       "      <td>329.437869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.380952</td>\n",
       "      <td>0.999113</td>\n",
       "      <td>12699.143426</td>\n",
       "      <td>107.956997</td>\n",
       "      <td>117.423956</td>\n",
       "      <td>23.314565</td>\n",
       "      <td>533.418074</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>118.347962</td>\n",
       "      <td>226.150000</td>\n",
       "      <td>138.850000</td>\n",
       "      <td>608.900000</td>\n",
       "      <td>29.072797</td>\n",
       "      <td>6.413459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1217.800000</td>\n",
       "      <td>0.999836</td>\n",
       "      <td>...</td>\n",
       "      <td>472.592775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.700000</td>\n",
       "      <td>0.999280</td>\n",
       "      <td>19279.322500</td>\n",
       "      <td>133.909430</td>\n",
       "      <td>143.790570</td>\n",
       "      <td>27.546486</td>\n",
       "      <td>685.998203</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>135.436282</td>\n",
       "      <td>184.500000</td>\n",
       "      <td>95.142857</td>\n",
       "      <td>309.190476</td>\n",
       "      <td>13.055264</td>\n",
       "      <td>5.737509</td>\n",
       "      <td>0.0</td>\n",
       "      <td>618.380952</td>\n",
       "      <td>0.999677</td>\n",
       "      <td>...</td>\n",
       "      <td>251.462283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>190.285714</td>\n",
       "      <td>0.998950</td>\n",
       "      <td>9052.163265</td>\n",
       "      <td>90.577022</td>\n",
       "      <td>99.708692</td>\n",
       "      <td>20.391388</td>\n",
       "      <td>434.406604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>121.169643</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>146.214286</td>\n",
       "      <td>595.571429</td>\n",
       "      <td>22.808542</td>\n",
       "      <td>6.391367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1191.142857</td>\n",
       "      <td>0.999832</td>\n",
       "      <td>...</td>\n",
       "      <td>463.505782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>292.428571</td>\n",
       "      <td>0.999317</td>\n",
       "      <td>21378.617343</td>\n",
       "      <td>141.222396</td>\n",
       "      <td>151.206175</td>\n",
       "      <td>28.715135</td>\n",
       "      <td>729.885521</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>131.127161</td>\n",
       "      <td>232.784314</td>\n",
       "      <td>144.588235</td>\n",
       "      <td>563.843137</td>\n",
       "      <td>11.948563</td>\n",
       "      <td>6.336725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1127.686275</td>\n",
       "      <td>0.999823</td>\n",
       "      <td>...</td>\n",
       "      <td>370.288279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.176471</td>\n",
       "      <td>0.999309</td>\n",
       "      <td>20905.757787</td>\n",
       "      <td>139.607453</td>\n",
       "      <td>149.569018</td>\n",
       "      <td>28.457868</td>\n",
       "      <td>720.162528</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>134.498092</td>\n",
       "      <td>210.212121</td>\n",
       "      <td>116.909091</td>\n",
       "      <td>594.848485</td>\n",
       "      <td>27.937685</td>\n",
       "      <td>6.390154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1189.696970</td>\n",
       "      <td>0.999832</td>\n",
       "      <td>...</td>\n",
       "      <td>393.416010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.818182</td>\n",
       "      <td>0.999145</td>\n",
       "      <td>13667.735535</td>\n",
       "      <td>112.139177</td>\n",
       "      <td>121.679005</td>\n",
       "      <td>24.006398</td>\n",
       "      <td>557.646299</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class    GLCM_pan  Mean_Green    Mean_Red    Mean_NIR     SD_pan  \\\n",
       "0      1  120.362774  205.500000  119.395349  416.581395  20.676318   \n",
       "1      1  124.739583  202.800000  115.333333  354.333333  16.707151   \n",
       "2      1  134.691964  199.285714  116.857143  477.857143  22.496712   \n",
       "3      1  127.946309  178.368421   92.368421  278.473684  14.977453   \n",
       "4      1  135.431548  197.000000  112.690476  532.952381  17.604193   \n",
       "5      1  118.347962  226.150000  138.850000  608.900000  29.072797   \n",
       "6      1  135.436282  184.500000   95.142857  309.190476  13.055264   \n",
       "7      1  121.169643  226.000000  146.214286  595.571429  22.808542   \n",
       "8      1  131.127161  232.784314  144.588235  563.843137  11.948563   \n",
       "9      1  134.498092  210.212121  116.909091  594.848485  27.937685   \n",
       "\n",
       "   Mean_NIR_log  Mean_NIR_Mean_NIR_1  Mean_NIR_Mean_NIR_2  \\\n",
       "0      6.034719                  0.0           833.162791   \n",
       "1      5.873338                  0.0           708.666667   \n",
       "2      6.171611                  0.0           955.714286   \n",
       "3      5.633266                  0.0           556.947368   \n",
       "4      6.280494                  0.0          1065.904762   \n",
       "5      6.413459                  0.0          1217.800000   \n",
       "6      5.737509                  0.0           618.380952   \n",
       "7      6.391367                  0.0          1191.142857   \n",
       "8      6.336725                  0.0          1127.686275   \n",
       "9      6.390154                  0.0          1189.696970   \n",
       "\n",
       "   Mean_NIR_Mean_NIR_3  ...  Mean_Red_SD_pan_44  Mean_Red_Mean_Red_1  \\\n",
       "0             0.999760  ...          367.286401                  0.0   \n",
       "1             0.999718  ...          331.464374                  0.0   \n",
       "2             0.999791  ...          368.901697                  0.0   \n",
       "3             0.999641  ...          255.969387                  0.0   \n",
       "4             0.999812  ...          329.437869                  0.0   \n",
       "5             0.999836  ...          472.592775                  0.0   \n",
       "6             0.999677  ...          251.462283                  0.0   \n",
       "7             0.999832  ...          463.505782                  0.0   \n",
       "8             0.999823  ...          370.288279                  0.0   \n",
       "9             0.999832  ...          393.416010                  0.0   \n",
       "\n",
       "   Mean_Red_Mean_Red_2  Mean_Red_Mean_Red_3  Mean_Red_Mean_Red_4  \\\n",
       "0           238.790698             0.999163         14255.249315   \n",
       "1           230.666667             0.999134         13301.777770   \n",
       "2           233.714286             0.999145         13655.591847   \n",
       "3           184.736842             0.998919          8531.925207   \n",
       "4           225.380952             0.999113         12699.143426   \n",
       "5           277.700000             0.999280         19279.322500   \n",
       "6           190.285714             0.998950          9052.163265   \n",
       "7           292.428571             0.999317         21378.617343   \n",
       "8           289.176471             0.999309         20905.757787   \n",
       "9           233.818182             0.999145         13667.735535   \n",
       "\n",
       "   Mean_Red_Mean_Red_11  Mean_Red_Mean_Red_22  Mean_Red_Mean_Red_33  \\\n",
       "0            114.604568            124.186130             24.412328   \n",
       "1            110.576874            120.089793             23.748439   \n",
       "2            112.087670            121.626616             23.997902   \n",
       "3             87.831868             96.904974             19.921786   \n",
       "4            107.956997            117.423956             23.314565   \n",
       "5            133.909430            143.790570             27.546486   \n",
       "6             90.577022             99.708692             20.391388   \n",
       "7            141.222396            151.206175             28.715135   \n",
       "8            139.607453            149.569018             28.457868   \n",
       "9            112.139177            121.679005             24.006398   \n",
       "\n",
       "   Mean_Red_Mean_Red_44  class_test  \n",
       "0            571.996957           1  \n",
       "1            548.578344          -1  \n",
       "2            557.347016          -1  \n",
       "3            419.034255          -1  \n",
       "4            533.418074          -1  \n",
       "5            685.998203          -1  \n",
       "6            434.406604           1  \n",
       "7            729.885521          -1  \n",
       "8            720.162528           1  \n",
       "9            557.646299          -1  \n",
       "\n",
       "[10 rows x 212 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68eef4e6-6659-4a00-88b8-ecc4bcce8758",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = mod_data.iloc[:,1:-1].values # just the X \n",
    "y_labeled = mod_data.iloc[:,-1].values # new class (just the P & U)\n",
    "y_positive = mod_data.iloc[:,0].values # original class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c50189-06bf-4cdc-ab6d-fa5743977169",
   "metadata": {},
   "source": [
    "1. RNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de0ec0b6-a266-4279-bc21-abd303d780f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 212) (19, 212)\n"
     ]
    }
   ],
   "source": [
    "mod_data = mod_data.sample(frac=1)\n",
    "neg_sample = mod_data[mod_data['class_test']==-1][:len(mod_data[mod_data['class_test']==1])]\n",
    "sample_test = mod_data[mod_data['class_test']==-1][len(mod_data[mod_data['class_test']==1]):]\n",
    "pos_sample = mod_data[mod_data['class_test']==1]\n",
    "print(neg_sample.shape, pos_sample.shape)\n",
    "sample_train = pd.concat([neg_sample, pos_sample]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7df11285-f134-40bb-91ce-47b55177c241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification results:\n",
      "f1: 38.93%\n",
      "roc: 95.37%\n",
      "recall: 94.44%\n",
      "precision: 24.52%\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier()\n",
    "\n",
    "model.fit(sample_train.iloc[:,1:-1].values, \n",
    "          sample_train.iloc[:,0].values)\n",
    "y_predict = model.predict(sample_test.iloc[:,1:-1].values)\n",
    "evaluate_results(sample_test.iloc[:,0].values, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5bbd6ac3-de21-420e-8f6b-5fe35108e947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f-score</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>normal_model</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.949417</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PU_learning_model</th>\n",
       "      <td>0.389313</td>\n",
       "      <td>0.953739</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.245192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    f-score   roc_auc    recall  precision\n",
       "normal_model       0.900000  0.949417  0.900000   0.900000\n",
       "PU_learning_model  0.389313  0.953739  0.944444   0.245192"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame(metrics,\n",
    "                          columns = ['f-score', 'roc_auc', 'recall', 'precision'],\n",
    "                          index = ['normal_model', 'PU_learning_model'])\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6686c82e-daf9-43b4-847c-30c77db3e66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_data = df_tr.copy()\n",
    "pos_ind = np.where(mod_data.iloc[:,0].values == 1)[0]\n",
    "np.random.shuffle(pos_ind)\n",
    "metrics1=[]\n",
    "alpha_list = np.linspace(0.1, 0.9, 9)\n",
    "for alpha in alpha_list:\n",
    "    pos_sample_len = int(np.ceil(alpha * len(pos_ind)))\n",
    "    pos_sample = pos_ind[:pos_sample_len]\n",
    "    mod_data['class_test'] = -1\n",
    "    mod_data.loc[pos_sample,'class_test'] = 1\n",
    "    mod_data = mod_data.sample(frac=1)\n",
    "    neg_sample = mod_data[mod_data['class_test']==-1][:len(mod_data[mod_data['class_test']==1])]\n",
    "    sample_test = mod_data[mod_data['class_test']==-1][len(mod_data[mod_data['class_test']==1]):]\n",
    "    pos_sample = mod_data[mod_data['class_test']==1]\n",
    "    sample_train = pd.concat([neg_sample, pos_sample]).sample(frac=1)\n",
    "    \n",
    "    model = xgb.XGBClassifier()\n",
    "\n",
    "    model.fit(sample_train.iloc[:,1:-1].values, sample_train.iloc[:,0].values)\n",
    "    y_predict = model.predict(sample_test.iloc[:,1:-1].values)\n",
    "    y_test1= sample_test.iloc[:,0].values\n",
    "    f1 = f1_score(y_test1, y_predict)\n",
    "    roc = roc_auc_score(y_test1, y_predict) \n",
    "    rec = recall_score(y_test1, y_predict, average='binary') \n",
    "    prc = precision_score(y_test1, y_predict, average='binary')\n",
    "    \n",
    "    metrics1.append([alpha,f1, roc, rec, prc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea7621a8-0834-4921-9a6b-3989ddd88ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>f-score</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.340206</td>\n",
       "      <td>0.969932</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.204969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.339181</td>\n",
       "      <td>0.973418</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.204225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.267380</td>\n",
       "      <td>0.967712</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.154321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.226221</td>\n",
       "      <td>0.964463</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.127536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.284615</td>\n",
       "      <td>0.978004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.165919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.192691</td>\n",
       "      <td>0.971209</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.106618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.265060</td>\n",
       "      <td>0.985521</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.118644</td>\n",
       "      <td>0.975268</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.063063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.110236</td>\n",
       "      <td>0.986541</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.058333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha   f-score   roc_auc  recall  precision\n",
       "0    0.1  0.340206  0.969932     1.0   0.204969\n",
       "1    0.2  0.339181  0.973418     1.0   0.204225\n",
       "2    0.3  0.267380  0.967712     1.0   0.154321\n",
       "3    0.4  0.226221  0.964463     1.0   0.127536\n",
       "4    0.5  0.284615  0.978004     1.0   0.165919\n",
       "5    0.6  0.192691  0.971209     1.0   0.106618\n",
       "6    0.7  0.265060  0.985521     1.0   0.152778\n",
       "7    0.8  0.118644  0.975268     1.0   0.063063\n",
       "8    0.9  0.110236  0.986541     1.0   0.058333"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df1 = pd.DataFrame(metrics1,\n",
    "                          columns = ['alpha','f-score', 'roc_auc', 'recall', 'precision'])\n",
    "metrics_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e82b6c-ce69-43ae-a658-c73df5dff05e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
